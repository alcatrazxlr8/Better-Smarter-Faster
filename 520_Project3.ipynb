{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DSQg8a0YkQ_u"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s-S84YE2G83y"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Graph:\n",
    "    def __init__ (self, node_num):\n",
    "        self.node_num = node_num\n",
    "\n",
    "        self.adj_list = {node : set() for node in range(node_num)}\n",
    "        self.visual = [] ## VIS\n",
    "\n",
    "        i=0\n",
    "        while i<node_num-1:\n",
    "            self.add_edge(i, i+1)\n",
    "            i=i+1\n",
    "        self.add_edge(self.node_num-1,0)    \n",
    "        \n",
    "        self.add_rand_edges()\n",
    "\n",
    "    def add_edge(self, node1, node2): ## --> O/P: updates adj_list\n",
    "        \n",
    "        ## since graph is undirected, we add bi-directional edges\n",
    "        \n",
    "        self.adj_list[node1].add(node2)\n",
    "        self.adj_list[node2].add(node1)\n",
    "\n",
    "        tmp = [node1, node2] ## VIS\n",
    "        self.visual.append(tmp) ## VIS\n",
    "\n",
    "    def get_deg(self, node): ## --> O/P: INT ## func to get degree of a node\n",
    "        return len(self.adj_list[node])\n",
    "\n",
    "    def get_next_moves(self, node):\n",
    "        return list(self.adj_list[node]) \n",
    "\n",
    "    def get_valid_neighbours(self, node): ## --> O/P: list of neighbors (e.g.: [1, 2, 3, ...] )\n",
    "\n",
    "        valid_neighbours = []\n",
    "\n",
    "        for i in range(-5, -1):\n",
    "            next = (node + i + self.node_num) % self.node_num ## the \"+ self.node_num\" handles negative cases\n",
    "            valid_neighbours.append(next)\n",
    "        for i in range(2, 6):\n",
    "            next = (node + i + self.node_num) % self.node_num ## the \"+ self.node_num\" handles negative cases\n",
    "            valid_neighbours.append(next)\n",
    "\n",
    "        return valid_neighbours\n",
    "    \n",
    "    def get_deg2_neighbours(self, node): ## --> O/P: list of neighbors with deg=2 [e.g.: [1, 2, 3, ...]]\n",
    "\n",
    "        valid_neighbours = self.get_valid_neighbours(node)\n",
    "        deg2_neighbours = []\n",
    "        for i in valid_neighbours:\n",
    "            if(self.get_deg(i) == 2):\n",
    "                deg2_neighbours.append(i)\n",
    "\n",
    "        return deg2_neighbours\n",
    "\n",
    "    def get_rand_node(self):\n",
    "        return random.choice(list(self.adj_list.keys()))\n",
    "\n",
    "    def add_rand_edges(self): ## --> O/P: updates adj_list\n",
    "        \n",
    "        total_nodes = list(self.adj_list.keys()) ## --> total_nodes = [0,1,......,10]\n",
    "        while(total_nodes):\n",
    "            x = random.choice(total_nodes)\n",
    "            valid_nbrs = self.get_deg2_neighbours(x)\n",
    "            if valid_nbrs:\n",
    "                y = random.choice(valid_nbrs) ## failing where it doesn't get deg2_neighbours\n",
    "                self.add_edge(x, y)\n",
    "                total_nodes.remove(y) ### fails where 'y' is NULL -----> FIXED\n",
    "                # print(y)\n",
    "            total_nodes.remove(x)\n",
    "\n",
    "    def getPath(self, goal, start, parent):\n",
    "\n",
    "        result = [goal]\n",
    "        while goal != start:\n",
    "            goal = parent[goal]    \n",
    "            result.append(goal)\n",
    "        # print (goal)\n",
    "\n",
    "        result.reverse()\n",
    "        return result\n",
    "\n",
    "    def BFS(self, start, goal):\n",
    "\n",
    "        fringe = [start]\n",
    "        visited = set()\n",
    "        parent = {}\n",
    "        visited.add(start)\n",
    "        \n",
    "        while(fringe):\n",
    "            current = fringe.pop(0) #Queue so pop(0) implementing FIFO\n",
    "            # visited.add(current) \n",
    "            if current == goal:\n",
    "            #print(len(visited))\n",
    "                return self.getPath(goal, start, parent)\n",
    "            #print (current,\"current\")\n",
    "            children = self.get_next_moves(current)\n",
    "            #print(children,\"test_BFS\")\n",
    "            for child in children:\n",
    "                if child not in visited:\n",
    "                    visited.add(child)\n",
    "                    fringe.append(child)\n",
    "                    parent[child] = current\n",
    "\n",
    "        return None\n",
    "\n",
    "    def print_adj_list(self):\n",
    "        for i in self.adj_list.keys():\n",
    "            print(i, self.adj_list[i])\n",
    "\n",
    "    ## VIS\n",
    "    def visualize(self):\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(self.visual)\n",
    "        nx.draw_networkx(G)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-yxLDJFBOrI1"
   },
   "outputs": [],
   "source": [
    "class Prey:\n",
    "    def __init__(self, graph):\n",
    "        self.loc = graph.get_rand_node()\n",
    "        self.graph = graph\n",
    "        \n",
    "    def move(self):\n",
    "\n",
    "        neighbours = self.graph.get_next_moves(self.loc)\n",
    "        neighbours.append(self.loc)\n",
    "        next = random.choice(neighbours)\n",
    "        self.loc = next\n",
    "        return self.loc\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.loc)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ov0kjS12TlE-"
   },
   "outputs": [],
   "source": [
    "class Predator:\n",
    "    def __init__(self, graph):\n",
    "        self.loc = graph.get_rand_node()\n",
    "        self.graph = graph\n",
    "\n",
    "    def move(self, agent_loc):\n",
    "        # assert self.loc != agent_loc ## but will this prevent agent from dying ??\n",
    "\n",
    "        neighbours = self.graph.get_next_moves(self.loc)\n",
    "\n",
    "        path = self.graph.BFS(self.loc, agent_loc)\n",
    "        self.loc = path[1]\n",
    "        return self.loc\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.loc)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.loc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dTxR9IzsSjiy"
   },
   "outputs": [],
   "source": [
    "# g1 = Graph(50)\n",
    "# nx.write_gpickle(g1, \"g1.gpickle\")\n",
    "g1 = nx.read_gpickle(\"g1.gpickle\")\n",
    "\n",
    "# # g2 = Graph(50)\n",
    "# # nx.write_gpickle(g1, \"g2.gpickle\")\n",
    "# g2 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g2.gpickle\")\n",
    "\n",
    "# # g3 = Graph(50)\n",
    "# # nx.write_gpickle(g1, \"g3.gpickle\")\n",
    "# g3 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g3.gpickle\")\n",
    "\n",
    "# # g4 = Graph(50)\n",
    "# # nx.write_gpickle(g1, \"g4.gpickle\")\n",
    "# g4 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g4.gpickle\")\n",
    "\n",
    "# # g5 = Graph(50)\n",
    "# # nx.write_gpickle(g1, \"g5.gpickle\")\n",
    "# g5 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g5.gpickle\")\n",
    "\n",
    "\n",
    "g = g1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDWchQhRJpG2"
   },
   "outputs": [],
   "source": [
    "# node_num = 50\n",
    "# g_test = Graph(node_num)\n",
    "# nx.write_gpickle(g_test, \"g_test.gpickle\")\n",
    "\n",
    "\n",
    "\n",
    "# # g.print_adj_list()\n",
    "\n",
    "# # g.visualize()\n",
    "\n",
    "# prey = Prey(g_test)\n",
    "# # prey2 = prey1\n",
    "# # prey2 = copy.deepcopy(prey1)\n",
    "# # prey1 = copy.copy(prey)\n",
    "# # prey2 = copy.copy(prey) ## ???? should I do deep or shallow copy of prey and pred if I want them to be separate for each agent but not have to write new code ?????\n",
    "# # prey3 = copy.copy(prey)\n",
    "# # prey4 = copy.copy(prey)\n",
    "# prey5 = copy.copy(prey)\n",
    "# # prey6 = copy.copy(prey)\n",
    "# # prey7 = copy.copy(prey)\n",
    "# # prey8 = copy.copy(prey)\n",
    "# # prey9 = copy.copy(prey)\n",
    "\n",
    "# pred = Predator(g_test)\n",
    "# # pred2 = pred1\n",
    "# # pred2 = copy.deepcopy(pred1)\n",
    "# # pred1 = copy.copy(pred)\n",
    "# # pred2 = copy.copy(pred)\n",
    "# # pred3 = copy.copy(pred)\n",
    "# # pred4 = copy.copy(pred)\n",
    "# pred5 = copy.copy(pred)\n",
    "# # pred6 = copy.copy(pred)\n",
    "# # pred7 = copy.copy(pred)\n",
    "# # pred8 = copy.copy(pred)\n",
    "# # pred9 = copy.copy(pred)\n",
    "\n",
    "# prey_belief = [1/(g_test.node_num-1)]*(g_test.node_num) ### [1/49]*50\n",
    "# pred_belief = [1/(g_test.node_num-1)]*(g_test.node_num)\n",
    "\n",
    "# threshold = 1000\n",
    "# loops = 1 ### CHANGE TO 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LlZqXxna6Tl6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m-TI5qXKXdx8"
   },
   "outputs": [],
   "source": [
    "# ####### DON'T RUN SINCE ALREADY STORED UTILITIES ####### RUN ONLY IF CALCULATING FOR NEW GRAPH ########\n",
    "# state_space = {}\n",
    "# def calc_state_space(g):\n",
    "#     for i in range(g.node_num):\n",
    "#         for j in range(g.node_num):\n",
    "#             for k in range(g.node_num):\n",
    "                \n",
    "#                 key = (i, j,  k)\n",
    "#                 # reward = [1]*graph.node_num\n",
    "#                 reward = 1\n",
    "#                 # util = [0]*graph.node_num\n",
    "#                 util = len(g.BFS(i, j))-1\n",
    "\n",
    "#                 state_space[key] = [reward, util]\n",
    "                \n",
    "# calc_state_space(g)\n",
    "# # print (state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4H8vSgcFeejH"
   },
   "outputs": [],
   "source": [
    "# ####### DON'T RUN SINCE ALREADY STORED UTILITIES ####### RUN ONLY IF CALCULATING FOR NEW GRAPH ########\n",
    "\n",
    "# for key in state_space:\n",
    "#     agent_loc, prey_loc, pred_loc = key\n",
    "    \n",
    "#     if agent_loc == prey_loc:\n",
    "#         state_space[key] = [0, state_space[key][1]]\n",
    "\n",
    "#     if agent_loc == pred_loc:\n",
    "#         state_space[key] = [math.inf, state_space[key][1]]\n",
    "\n",
    "# # print(state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsiyDfq6XM9i",
    "outputId": "63fe1450-59ec-4283-90a9-949b63214dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "################ VALUE ITERATION ###################\n",
    "\n",
    "### PRINTING TO FILE\n",
    "#\n",
    "f = open(\"/content/drive/MyDrive/Colab Notebooks/util_file.txt\", \"w\")\n",
    "\n",
    "error = True\n",
    "count = 0\n",
    "while error:\n",
    "\n",
    "    error = False\n",
    "    state_space_copy = copy.copy(state_space)\n",
    "\n",
    "    for key in state_space:\n",
    "        min_sum_arr = []\n",
    "        \n",
    "        agent_loc, prey_loc, pred_loc = key\n",
    "\n",
    "        # #### for each state, agent = prey -> util=0\n",
    "        #     cont\n",
    "        if agent_loc == prey_loc:\n",
    "            state_space[key] = [state_space[key][0], 0]\n",
    "            continue\n",
    "\n",
    "        # #### for each state, agent = pred -> util = math.INF\n",
    "        #     cont\n",
    "        # elif agent_loc == pred_loc or agent_loc == pred_loc - 1 or agent_loc == pred_loc + 1:\n",
    "        elif agent_loc == pred_loc:    \n",
    "            state_space[key] = [state_space[key][0], math.inf]          \n",
    "            continue\n",
    "\n",
    "        ### AGENT\n",
    "        agent_states = {}\n",
    "\n",
    "        agent_nbrs = g.get_next_moves(agent_loc)\n",
    "        \n",
    "        min_sum_arr = []###\n",
    "        for nbr1 in agent_nbrs:\n",
    "\n",
    "            ## if nbr1=prey -> sum arr append 0 \n",
    "            ##      cont\n",
    "            if nbr1 == prey_loc:\n",
    "                min_sum_arr.append(0)\n",
    "                continue\n",
    "            \n",
    "            elif nbr1 == pred_loc:\n",
    "                min_sum_arr.append(math.inf)\n",
    "                continue\n",
    "\n",
    "            denom1 = g.get_deg(agent_loc)\n",
    "            agent_states[nbr1] = 1/denom1\n",
    "\n",
    "            prey_states = {}\n",
    "            pred_states = {}\n",
    "\n",
    "            sum = 0\n",
    "            # min_sum_arr = []\n",
    "\n",
    "            ### PREY\n",
    "            # prey_states = {}\n",
    "\n",
    "            prey_nbrs = g.get_next_moves(prey_loc)\n",
    "            prey_nbrs.append(prey_loc)\n",
    "\n",
    "            for nbr2 in prey_nbrs:\n",
    "                denom2 = g.get_deg(prey_loc) + 1\n",
    "                tmp2 = 1/denom2\n",
    "                prey_states[nbr2] = tmp2\n",
    "\n",
    "                ### PRED\n",
    "                # pred_states = {}\n",
    "\n",
    "                pred_nbrs = g.get_next_moves(pred_loc)\n",
    "\n",
    "                ##########################################\n",
    "                ### UNDISTRACTED PRED (FROM PROJECT 2) ###\n",
    "                ##########################################\n",
    "                for nbr3 in pred_nbrs:\n",
    "                    denom3 = g.get_deg(pred_loc)\n",
    "                    tmp3 = 1/denom3\n",
    "                    pred_states[nbr3] = tmp3\n",
    "\n",
    "                ########################################\n",
    "                ### DISTRACTED PRED (FROM PROJECT 2) ###\n",
    "                ########################################\n",
    "\n",
    "                # # for i in pred_nbrs:\n",
    "\n",
    "                #     # nbrs_i = g.get_next_moves(i)\n",
    "                    \n",
    "                # for nbr3 in pred_nbrs:\n",
    "                #     nbr_bfs = {}\n",
    "                    \n",
    "                #     nbr_nbrs_i = g.get_next_moves(nbr3)\n",
    "                #     for nbr_nbr in nbr_nbrs_i:\n",
    "                #         bfs = g.BFS(nbr_nbr, agent_loc)\n",
    "                #         nbr_bfs[nbr_nbr] = len(bfs)\n",
    "\n",
    "                #     min_bfs = min(nbr_bfs.values())\n",
    "\n",
    "                #     nbr_min_path_len = [key for key, value in nbr_bfs.items() if value == min_bfs]\n",
    "\n",
    "                #     x = len(nbr_min_path_len)\n",
    "\n",
    "                #     if i in nbr_min_path_len:\n",
    "                #         pred_states[nbr3] = (0.4/g.get_deg(nbr3))+(0.6/x)\n",
    "\n",
    "                #     else:\n",
    "                #         pred_states[nbr3] = 0.4/g.get_deg(nbr3)\n",
    "                \n",
    "                ###########################################\n",
    "\n",
    "                    sum += (state_space[(nbr1,nbr2,nbr3)][1] * tmp2 * tmp3)\n",
    "\n",
    "            sum += state_space[(nbr1,nbr2,nbr3)][0]\n",
    "            min_sum_arr.append(sum)\n",
    "        \n",
    "        if agent_loc in pred_nbrs:\n",
    "            min_sum_arr = [math.inf]\n",
    "\n",
    "        state_space[key] = [state_space[key][0], min(min_sum_arr)] ##UPDATING UTIL ##UPDATING UTIL\n",
    "        \n",
    "    ## WE RUN TILL ERROR CONVERGES\n",
    "    for key in state_space:\n",
    "        if abs(state_space[key][1] - state_space_copy[key][1]) > 0.0001:\n",
    "            error = True\n",
    "            break\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "\n",
    "print(count)\n",
    "\n",
    "for key in state_space:\n",
    "    print(key, state_space[key], file = f)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xqE6e3vtJqdY"
   },
   "outputs": [],
   "source": [
    "########## ---- RUN THIS ONLY WHEN CALCULATING U* FOR NEW GRAPH ---- ###########\n",
    "\n",
    "# from networkx.readwrite import gpickle\n",
    "# f1 = open(\"/content/drive/MyDrive/Colab Notebooks/state_space\", \"wb\")\n",
    "# # nx.gpickle.\n",
    "# pickle.dump(state_space, f1)\n",
    "# f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iMqbQEdmKm_W"
   },
   "outputs": [],
   "source": [
    "######## ---- RUN THIS EACH TIME WHEN RECONNECTING TO RUNTIME ALONG W/ CELLS FROM STARTING TILL GRAPH INIT CELL ---- #########\n",
    "\n",
    "f2 = open(\"g1_state_space\", \"rb\")\n",
    "state_space =  pickle.load(f2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xoHO1qZny_m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PCMDV7GGBq0U"
   },
   "outputs": [],
   "source": [
    "class uStarAgent:\n",
    "    \n",
    "    def __init__(self, graph, prey_loc, pred_loc, state_space, dbg=False):\n",
    "\n",
    "        self.graph = graph\n",
    "        self.agent_loc = graph.get_rand_node()\n",
    "        self.dbg = dbg\n",
    "        self.prey_loc = prey_loc\n",
    "        self.pred_loc = pred_loc\n",
    "        self.state_space = copy.copy(state_space)\n",
    "\n",
    "        # while prey_loc == self.agent_loc or pred_loc == self.agent_loc or pred_loc == self.agent_loc + 1 or pred_loc == self.agent_loc - 1:\n",
    "        while prey_loc == self.agent_loc or pred_loc == self.agent_loc or state_space[(self.agent_loc, prey_loc, pred_loc)][1] == math.inf:\n",
    "            self.agent_loc = graph.get_rand_node()\n",
    "\n",
    "\n",
    "    def debug(self, *args):\n",
    "        if self.dbg:\n",
    "            print(\"AgentU: \", args)\n",
    "\n",
    "\n",
    "    def isPrey(self, loc, prey_loc):\n",
    "        if self.agent_loc == prey_loc:\n",
    "            return True\n",
    "\n",
    "    def isPred(self, loc, pred_loc):\n",
    "        if self.agent_loc == pred_loc:\n",
    "            return True\n",
    "\n",
    "\n",
    "    def move(self, prey_loc, pred_loc, state_space):\n",
    "\n",
    "        agent_nbrs = self.graph.get_next_moves(self.agent_loc)\n",
    "\n",
    "        agent_nbr_util = {}\n",
    "\n",
    "        for nbr in agent_nbrs:\n",
    "            # agent_nbr_util[nbr] = state_space[(nbr, self.prey_loc, self.pred_loc)][1]\n",
    "            agent_nbr_util[nbr] = state_space[(nbr, prey_loc, pred_loc)][1]\n",
    "\n",
    "        \n",
    "        min_util = min(agent_nbr_util.values())\n",
    "\n",
    "        for key in agent_nbr_util:\n",
    "            if min_util == agent_nbr_util[key]:\n",
    "                minm = key\n",
    "\n",
    "        agentU.debug(\"AGENT NBR UTIL: \", agent_nbr_util, \"(\",nbr, prey_loc, pred_loc,\")\")\n",
    "\n",
    "\n",
    "        self.agent_loc = minm\n",
    "\n",
    "        return self.agent_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35f7zra-zDMy",
    "outputId": "ec748981-2b7a-4626-d466-9f987ca01606"
   },
   "outputs": [],
   "source": [
    "# g1 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g1.gpickle\")\n",
    "threshold = 5000\n",
    "loops = 3000\n",
    "hung = 0\n",
    "cnt = 0\n",
    "ans = 0\n",
    "\n",
    "survival = []\n",
    "\n",
    "for i in range(loops):\n",
    "    preyU = Prey(g)\n",
    "    predU = Predator(g)\n",
    "\n",
    "    agentU = uStarAgent(g, preyU.loc, predU.loc, state_space, False)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while agentU.agent_loc != preyU.loc and agentU.agent_loc != predU.loc:\n",
    "        \n",
    "        if count > threshold:\n",
    "            print(\"HUNG SIMULATION\")\n",
    "            hung += 1\n",
    "            continue\n",
    "\n",
    "        agentU.debug(\"BEFORE\", agentU.agent_loc, preyU.loc, predU.loc)\n",
    "\n",
    "        agentU.agent_loc = agentU.move(preyU.loc, predU.loc, state_space)\n",
    "        \n",
    "        if agentU.isPred(agentU.agent_loc, predU.loc) and agentU.isPrey(agentU.agent_loc, preyU.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "\n",
    "        elif agentU.isPred(agentU.agent_loc, predU.loc):\n",
    "            print(False, agentU.agent_loc, preyU.loc, predU.loc)\n",
    "            continue\n",
    "\n",
    "        elif agentU.isPrey(agentU.agent_loc, preyU.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "        \n",
    "        preyU.loc = preyU.move()\n",
    "        \n",
    "        predU.loc = predU.move(agentU.agent_loc)\n",
    "        \n",
    "        if agentU.isPred(agentU.agent_loc, predU.loc) and agentU.isPrey(agentU.agent_loc, preyU.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "\n",
    "        elif agentU.isPred(agentU.agent_loc, predU.loc):\n",
    "            print(False, agentU.agent_loc, preyU.loc, predU.loc)\n",
    "            continue\n",
    "\n",
    "        elif agentU.isPrey(agentU.agent_loc, preyU.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue      \n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    cnt += 1\n",
    "    survival.append(count)\n",
    "    # print(\"cnt: \", cnt, \"Steps : \", count)\n",
    "\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"CNT: \", cnt)\n",
    "print(\"TRUE: \", ans)\n",
    "print(\"FALSE: \", cnt-(ans+hung))\n",
    "print(\"HUNG: \", hung)\n",
    "# avg_steps = sum(survival)\n",
    "sum = 0\n",
    "for i in survival:\n",
    "    sum += i\n",
    "\n",
    "print(\"AVG. STEPS: \", sum/loops)\n",
    "print(\"============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wqeI-gYghgi8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class uPartAgent:\n",
    "    \n",
    "    def __init__(self, graph, prey_loc, pred_loc, prey_belief, state_space, dbg=False):\n",
    "\n",
    "        self.graph = graph\n",
    "        self.agent_loc = graph.get_rand_node()\n",
    "        self.dbg = dbg\n",
    "        self.prey_loc = prey_loc\n",
    "        self.pred_loc = pred_loc\n",
    "        self.state_space = copy.copy(state_space)\n",
    "        \n",
    "        self.vpart_dict = {}\n",
    "\n",
    "        # while prey_loc == self.agent_loc or pred_loc == self.agent_loc or pred_loc == self.agent_loc + 1 or pred_loc == self.agent_loc - 1:\n",
    "        while prey_loc == self.agent_loc or pred_loc == self.agent_loc or state_space[(self.agent_loc, prey_loc, pred_loc)][1] == math.inf:\n",
    "            self.agent_loc = graph.get_rand_node()\n",
    "\n",
    "        self.prey_belief = prey_belief\n",
    "        self.prey_belief[self.agent_loc] = 0\n",
    "\n",
    "    def debug(self, *args):\n",
    "        if self.dbg:\n",
    "            print(\"AgentUPart: \", args)\n",
    "\n",
    "\n",
    "    def isPrey(self, loc, prey_loc):\n",
    "        if self.agent_loc == prey_loc:\n",
    "            return True\n",
    "\n",
    "    def isPred(self, loc, pred_loc):\n",
    "        if self.agent_loc == pred_loc:\n",
    "            return True\n",
    "\n",
    "    def survey(self, prey_belief):\n",
    "        ## look at current list of belief - select max prob nodes (if multiple - select one at random)\n",
    "        new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "\n",
    "        val_max = max(prey_belief)\n",
    "        # idx_max = 0 ## not needed\n",
    "        idx_max_list = []\n",
    "\n",
    "        for i in range(len(prey_belief)):\n",
    "            if prey_belief[i] >= val_max:\n",
    "                # val_max = prey_belief[i]\n",
    "                idx_max_list.append(i)\n",
    "\n",
    "        rand_idx_max = random.choice(idx_max_list)\n",
    "\n",
    "        # ### check if prey is there or not\n",
    "        # \n",
    "        if self.isPrey(rand_idx_max, self.prey_loc):\n",
    "            # print(\"IS PREY EXECUTED: \", rand_idx_max)\n",
    "            for i in range(self.graph.node_num):\n",
    "                prey_belief[i] = 0.0\n",
    "            prey_belief[rand_idx_max] = 1.0\n",
    "            # print (\"ISPREY: \", prey_belief)\n",
    "            return prey_belief\n",
    "        #     update_belief ## according to prey found in survey logic\n",
    "                \n",
    "        else:\n",
    "        #     update_belief ## according to prey not found in survey logic\n",
    "            for i in range(self.graph.node_num):\n",
    "                # denom = sum(prey_belief)-prey_belief[rand_idx_max]\n",
    "                denom = 1-prey_belief[rand_idx_max]\n",
    "                new_prey_belief[i] = prey_belief[i]/denom\n",
    "                new_prey_belief[rand_idx_max] = 0.0\n",
    "\n",
    "        prey_belief = new_prey_belief\n",
    "        return prey_belief\n",
    "\n",
    "    def agent_move_prey_belief(self, prey_loc, prey_belief):\n",
    "\n",
    "        new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "        # new_prey_belief = prey_belief\n",
    "\n",
    "        if self.isPrey(self.agent_loc, prey_loc):\n",
    "            for i in range(self.graph.node_num): ###///this will not actually happen since the game would be over\n",
    "                prey_belief[i] = 0.0\n",
    "            prey_belief[self.agent_loc] = 1.0\n",
    "            return prey_belief  \n",
    "        \n",
    "        else:\n",
    "        #   update_belief ## according to prey not found in survey logic\n",
    "            for i in range(self.graph.node_num):\n",
    "                # denom = sum(prey_belief)-prey_belief[self.agent_loc]\n",
    "                denom = 1.0-prey_belief[self.agent_loc]\n",
    "                new_prey_belief[i] = prey_belief[i]/denom\n",
    "                new_prey_belief[self.agent_loc] = 0.0\n",
    "\n",
    "        prey_belief = new_prey_belief\n",
    "        return prey_belief\n",
    "\n",
    "    def prey_move_prey_belief(self, prey_loc, prey_belief):\n",
    "\n",
    "        new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "        # new_prey_belief = prey_belief\n",
    "\n",
    "        for i in range(self.graph.node_num):\n",
    "            nbrs_i = self.graph.get_next_moves(i)\n",
    "            nbrs_i.append(i)\n",
    "            for nbr in nbrs_i:\n",
    "                denom = self.graph.get_deg(nbr) + 1\n",
    "                new_prey_belief[i] += prey_belief[nbr] / denom\n",
    "\n",
    "        prey_belief = new_prey_belief\n",
    "\n",
    "        prey_belief = self.agent_move_prey_belief(prey_loc, prey_belief)\n",
    "\n",
    "        # prey_belief = new_prey_belief\n",
    "        return prey_belief\n",
    "\n",
    "\n",
    "    def move(self, prey_loc, pred_loc, prey_belief, state_space):\n",
    "\n",
    "        prey_belief = self.survey(prey_belief)\n",
    "\n",
    "        agent_nbrs = self.graph.get_next_moves(self.agent_loc)\n",
    "\n",
    "        agent_nbr_util = {}\n",
    "        tmp_list = [] ##########\n",
    "        for nbr in agent_nbrs:\n",
    "            # agent_nbr_util[nbr] = state_space[(nbr, prey_loc, pred_loc)][1]\n",
    "            tmp = 0\n",
    "            tmp_dist = 0 ###########\n",
    "            tmp2_list = [] ##########\n",
    "            for i in range(len(prey_belief)):\n",
    "                if state_space[(nbr, i, pred_loc)][1] == math.inf:\n",
    "                    tmp = math.inf\n",
    "                    break\n",
    "                    \n",
    "                tmp += state_space[(nbr, i, pred_loc)][1] * prey_belief[i]\n",
    "                tmp_dist += (len(g.BFS(nbr, prey_loc))) * prey_belief[i] #############\n",
    "                \n",
    "            agent_nbr_util[nbr] = tmp\n",
    "            \n",
    "            tmp2_list.append(tmp_dist) #################\n",
    "            tmp2_list.append((len(g.BFS(nbr, pred_loc))-1)) #################\n",
    "            tmp2_list.append(tmp) #################\n",
    "            \n",
    "            tmp_list.append(tmp2_list) ###############\n",
    "            \n",
    "        min_util = min(agent_nbr_util.values())\n",
    "        agentUPart.debug(\"min_util\", min_util)\n",
    "        for key in agent_nbr_util:\n",
    "            if min_util == agent_nbr_util[key]:\n",
    "                minm = key\n",
    "\n",
    "        agentUPart.debug(\"AGENT NBR UTIL: \", agent_nbr_util, \"(\",nbr, prey_loc, pred_loc,\")\")\n",
    "\n",
    "        self.agent_loc = minm\n",
    "\n",
    "        prey_belief = self.agent_move_prey_belief(prey_loc, prey_belief)\n",
    "\n",
    "        return self.agent_loc, tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctTy8Fs6QNWa",
    "outputId": "aeb826fe-c264-4b8c-d1a2-f5ce17528bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print (math.inf * 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8L8iDf4Jk7Qm",
    "outputId": "d28286bf-e47e-43a7-a740-0c074230de65"
   },
   "outputs": [],
   "source": [
    "# g1 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g1.gpickle\")\n",
    "threshold = 5000\n",
    "loops = 3000\n",
    "hung = 0\n",
    "cnt = 0\n",
    "ans = 0\n",
    "\n",
    "survival = []\n",
    "vpart_data = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(loops):\n",
    "    preyUPart = Prey(g)\n",
    "    predUPart = Predator(g)\n",
    "    prey_belief = [1/(g.node_num-1)]*(g.node_num) ### [1/49]*50\n",
    "\n",
    "    agentUPart = uPartAgent(g, preyUPart.loc, predUPart.loc, prey_belief, state_space, False)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while agentUPart.agent_loc != preyUPart.loc and agentUPart.agent_loc != predUPart.loc:\n",
    "        \n",
    "        if count > threshold:\n",
    "            print(\"HUNG SIMULATION\")\n",
    "            hung += 1\n",
    "            continue\n",
    "\n",
    "        # agentUPart.debug(\"BEFORE\", agentUPart.agent_loc, preyUPart.loc, predUPart.loc)\n",
    "\n",
    "        agentUPart.agent_loc, tmp_list = agentUPart.move(preyUPart.loc, predUPart.loc, prey_belief, state_space)\n",
    "        for data in tmp_list:\n",
    "            vpart_data.append(data)\n",
    "        prey_belief = agentUPart.agent_move_prey_belief(preyUPart.loc, prey_belief)\n",
    "\n",
    "        if agentUPart.isPred(agentUPart.agent_loc, predUPart.loc) and agentUPart.isPrey(agentUPart.agent_loc, preyUPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "\n",
    "        elif agentUPart.isPred(agentUPart.agent_loc, predUPart.loc):\n",
    "            print(False, agentUPart.agent_loc, preyUPart.loc, predUPart.loc)\n",
    "            continue\n",
    "\n",
    "        elif agentUPart.isPrey(agentUPart.agent_loc, preyUPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "        \n",
    "        preyUPart.loc = preyUPart.move()\n",
    "        prey_belief = agentUPart.prey_move_prey_belief(preyUPart.loc, prey_belief) \n",
    "        \n",
    "        predUPart.loc = predUPart.move(agentUPart.agent_loc)\n",
    "        \n",
    "        if agentUPart.isPred(agentUPart.agent_loc, predUPart.loc) and agentUPart.isPrey(agentUPart.agent_loc, preyUPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "\n",
    "        elif agentUPart.isPred(agentUPart.agent_loc, predUPart.loc):\n",
    "            print(False, agentUPart.agent_loc, preyUPart.loc)\n",
    "            continue\n",
    "\n",
    "        elif agentUPart.isPrey(agentUPart.agent_loc, preyUPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue      \n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    cnt += 1\n",
    "    survival.append(count)\n",
    "    # print(\"cnt: \", cnt, \"Steps : \", count)\n",
    "\n",
    "    \n",
    "# print(vpart_data)\n",
    "print(\"============================\")\n",
    "print(\"CNT: \", cnt)\n",
    "print(\"TRUE: \", ans)\n",
    "print(\"FALSE: \", cnt-(ans+hung))\n",
    "print(\"HUNG: \", hung)\n",
    "# avg_steps = sum(survival)\n",
    "sum = 0\n",
    "for i in survival:\n",
    "    sum += i\n",
    "\n",
    "print(\"AVG. STEPS: \", sum/loops)\n",
    "print(\"============================\")\n",
    "######################################\n",
    "\n",
    "# fv = open(\"vpart_input\", \"wb\")\n",
    "# # nx.gpickle.\n",
    "# pickle.dump(vpart_data, fv)\n",
    "# fv.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " STATE: (2, 32, 23) ; Agent1: 2 ; Agent2: 3 ; U*Agent: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fv = open(\"vpart_input\", \"wb\")\n",
    "# nx.gpickle.\n",
    "pickle.dump(vpart_data, fv)\n",
    "fv.close()\n",
    "\n",
    "fv = open(\"vpart_input\", \"rb\")\n",
    "vpart_input = pickle.load(fv)\n",
    "fv.close()\n",
    "\n",
    "# print(type(vpart_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, inf], [0, 1, inf], [0, 3, inf], [11.999999999999998, 3, 11.277225652623718], [0, 1, inf], [10.999999999999995, 3, 10.822674341122845], [0, 1, inf], [0, 3, inf], [11.0, 3, 10.28140371450237], [0, 1, inf], [0, 1, inf], [10.999999999999995, 3, 9.793109976074563], [10.999999999999995, 3, 9.793109961434588], [0, 1, inf], [0, 3, inf], [10.999999999999996, 3, 9.336667167821352], [9.0, 3, 9.038631710473654], [0, 1, inf], [0, 3, inf], [0, 1, inf], [7.999999999999998, 3, 8.685763429079465], [0, 3, inf], [6.999999999999999, 3, 8.405765424369667], [6.999999999999999, 3, 8.405771519251354], [0, 1, inf], [0.05748629600050944, 1, inf], [6.999999999999999, 3, 8.192470717566472], [6.999999999999999, 3, 8.40304853007762], [0, 1, inf], [5.999999999999997, 3, 8.326933082503567], [6.999999999999997, 2, 8.844684835367289], [3.999999999999999, 3, 7.9970126024318535], [0, 1, inf], [0, 2, inf], [3.9999999999999987, 3, 7.575197101338093], [0, 1, inf], [0, 3, inf], [0, 1, inf], [0, 3, inf], [2.9999999999999996, 3, 7.28949004586116], [0, 1, inf], [1.0000000000000002, 3, 7.1553957498951135], [2.999999999999999, 3, 6.756292809681415], [1.0, 3, 0.0], [2.0, 3, 3.7099256558229077], [0, 1, inf], [0.9999999999999999, 3, 0.0], [2.9999999999999996, 2, 10.700290122943152], [0, 1, inf], [0, 2, inf], [0, 1, inf], [0.9999999999999999, 3, 2.5110769994581745], [0, 1, inf], [3.0000000000000004, 2, 7.349730053112469], [0.9999999999999999, 3, 8.6875483857808], [0, 0, inf], [2.999999999999999, 2, 6.920798904779629], [4.999999999999998, 2, 8.20425625624137], [0, 2, inf], [0, 0, inf], [1.0, 2, 7.910121021856817], [0.9999999999999999, 2, 7.965066292018257], [0, 0, inf], [1.9999999999999998, 2, 7.80088057826464], [3.0000000000000004, 2, 5.328074795227441], [2.0, 2, 15.905797033312224], [0, 0, inf], [0, 0, inf], [4.999999999999999, 2, 3.854996098666264], [0, 2, inf], [0, 0, inf], [5.999999999999997, 2, 5.19882464870453], [5.999999999999997, 2, 3.7784394617247337], [0, 0, inf], [3.999999999999999, 2, 8.850801577077696], [5.999999999999999, 2, 6.88078209721261], [0, 2, inf], [0, 0, inf], [7.0, 2, 6.31566632559383], [8.0, 2, 6.500436367766638], [0, 2, inf], [0, 0, inf], [9.999999999999998, 2, 10.379553001919463], [9.999999999999998, 2, 5.6144751523918135], [0, 0, inf], [0, 0, inf], [8.0, 2, 3.6964062851082877], [9.999999999999998, 2, 15.588423124626875], [0, 0, inf], [7.999999999999998, 2, 1.9375020517689936], [6.999999999999997, 2, 4.459056873856349], [0, 0, inf], [6.999999999999997, 2, 2.3452190108636137], [6.0, 2, 5.4521880369047455], [0, 0, inf], [8.0, 2, 9.804160008476398], [0, 2, inf], [5.0, 2, 5.609415020792852], [0, 0, inf], [3.0, 2, 10.777377346030358], [0, 0, inf], [5.000000000000002, 2, 6.035443401231351], [0, 0, inf], [3.9999999999999996, 2, 8.649401891597293], [6.0, 2, 6.080351397388992], [0, 2, inf], [0, 0, inf], [6.0, 2, 10.993448010528587], [6.0, 2, 12.484078955076955], [0, 2, inf], [0, 0, inf], [6.0, 2, 14.333943604816891], [6.0, 2, 10.101921169327692], [0, 0, inf], [0, 0, inf], [5.999999999999997, 2, 5.2885478616367685], [7.999999999999999, 2, 16.788203340898587], [0, 0, inf], [3.9999999999999987, 2, 2.376359884077398], [2.0, 2, 3.5234953815208843], [0, 0, inf], [2.9999999999999996, 2, 2.9395363420599785], [1.0, 2, 4.694094727557447], [0, 0, inf], [3.0, 2, 11.068937665906583], [0, 2, inf], [2.0000000000000004, 2, 3.9558458560383754], [0, 0, inf], [1.9999999999999998, 2, 8.496173293353717], [0, 0, inf], [1.9999999999999998, 2, 7.5937690523697325], [0, 0, inf], [2.0, 2, 6.294335771138726], [3.0, 2, 8.977369327439627], [0, 2, inf], [0, 0, inf], [2.9999999999999996, 2, 7.770703715954596], [2.0000000000000004, 2, 8.312251808368803], [0, 0, inf], [2.0000000000000004, 2, 7.832351765823067], [1.0, 2, 6.377043353062536], [3.0000000000000013, 2, 14.413966614879767], [0, 0, inf], [0, 0, inf], [1.0000000000000002, 2, 4.851317602175159], [0, 2, inf], [0, 0, inf], [1.0000000000000002, 2, 6.0783242362465995], [3.0000000000000004, 2, 4.7854403206572815], [0, 0, inf], [3.0000000000000004, 2, 9.235386785975699], [2.000000000000001, 2, 7.686846875295971], [0, 2, inf], [0, 0, inf], [1.0, 2, 6.31566632559383], [3.0, 2, 6.500436367766638], [0, 2, inf], [0, 0, inf], [4.0, 2, 10.379553001919463], [2.0, 2, 5.6144751523918135], [0, 0, inf], [0, 0, inf], [0.0, 2, 3.6964062851082877], [2.0, 2, 15.588423124626875], [8.000000000000005, 5, 8.837124950269736], [10.000000000000002, 5, 10.220442856755945], [10.000000000000002, 5, 10.322102029540348], [8.999999999999996, 5, 10.474410887391235], [8.999999999999996, 3, 10.413510869716733], [6.9999999999999964, 5, 9.12765688542126], [7.999999999999996, 3, 10.317064850928958], [5.999999999999997, 5, 8.907502479426729], [6.999999999999997, 5, 9.778473957703882], [5.000000000000002, 5, 8.663489894158877], [5.999999999999999, 5, 9.523874347012306], [6.999999999999997, 3, 10.281953617799191], [5.999999999999999, 5, 9.277659922316424], [7.000000000000001, 3, 10.14890723068573], [4.999999999999999, 5, 8.496631238417102], [5.0, 5, 8.316698092725627], [6.999999999999998, 3, 9.782421344659241], [5.0, 5, 8.326523653749474], [4.9999999999999964, 4, 9.704582414201619], [2.999999999999999, 5, 8.307389899361617], [4.9999999999999964, 3, 9.781615016611068], [3.9999999999999996, 3, 9.57876485523927], [1.9999999999999998, 5, 8.014740651714327], [3.0000000000000018, 5, 8.028299908273208], [1.9999999999999996, 4, 8.647758261639419], [1.9999999999999996, 3, 9.1958027384037], [0.0, 5, 7.7154190348965965], [3.0, 6, 7.773177041247567], [4.000000000000003, 6, 7.331214918519837], [2.0000000000000013, 4, 8.06558991850614], [4.999999999999998, 6, 7.5695888359873535], [2.9999999999999982, 4, 7.933822715898978], [4.000000000000003, 4, 8.321444553307995], [6.000000000000001, 6, 8.32580994111692], [3.9999999999999996, 4, 8.244522913913004], [6.000000000000001, 6, 7.972698200382968], [5.000000000000001, 4, 9.0378114421116], [7.000000000000003, 6, 8.428147781161599], [5.000000000000001, 4, 9.041943370223654], [6.999999999999999, 5, 9.584585663528532], [7.999999999999999, 6, 8.360509421570512], [6.000000000000001, 4, 9.148807397161605], [8.0, 4, 9.236250659467503], [9.0, 5, 9.611191093227614], [10.000000000000004, 6, 8.515573458092685], [11.000000000000004, 6, 8.586609333366454], [9.0, 4, 9.390718852473608], [10.0, 5, 9.846902181179512], [12.0, 6, 10.0122595155631], [9.999999999999998, 6, 8.699432760699237], [11.000000000000005, 4, 9.950455542487955], [11.0, 4, 9.676710215597632], [11.0, 6, 9.796079099517017], [9.0, 6, 8.397810705229443], [9.000000000000002, 6, 8.002111834247467], [11.000000000000002, 4, 9.357148567005254], [11.000000000000002, 6, 9.417029524206528], [11.000000000000002, 6, 9.043152043476294], [9.0, 6, 7.575988828004783], [11.000000000000002, 4, 8.879188165337471], [10.0, 4, 8.373397795803493], [7.999999999999999, 6, 7.196724218102809], [7.999999999999999, 6, 7.1967242179461595], [8.000000000000004, 4, 7.870375468396756], [8.000000000000004, 6, 8.27171879000483], [6.000000000000002, 6, 6.855325238743041], [4.000000000000001, 6, 6.669926968225627], [6.000000000000002, 4, 7.767674065068152], [6.000000000000002, 6, 8.029467798723502], [3.9999999999999996, 4, 7.636028549643818], [1.9999999999999998, 6, 6.604962078561713], [3.9999999999999996, 4, 7.6820061881829975], [2.0, 6, 6.606297050401065], [1.0, 6, 6.6571121472493475], [3.0, 4, 7.654886670228701], [2.0, 4, 7.521492608226651], [0.0, 6, 7.282243782212052], [2.0, 6, 7.003807169053822], [0.0, 4, 7.921959012023684], [1.9999999999999998, 4, 7.896359059720733], [1.9999999999999998, 6, 7.052349838146541], [4.0, 6, 7.029250844862902], [4.0, 6, 7.082733136701852], [2.0, 4, 8.06554512844888], [4.000000000000001, 6, 7.0503060968185185], [2.0000000000000004, 4, 8.066131456561372], [2.0000000000000004, 4, 8.019250086731965], [2.0, 4, 8.168356400095933], [2.0, 4, 8.305171336024774], [4.0, 6, 7.128511801095139], [4.000000000000002, 4, 8.097444030873335], [6.0, 6, 7.31773993309757], [6.0, 6, 7.235097407382193], [5.999999999999999, 6, 7.867355046876576], [6.999999999999998, 6, 7.334631686758528], [4.999999999999999, 4, 8.223121960788898], [7.000000000000001, 6, 7.162771902890805], [7.000000000000001, 6, 7.332493333048143], [4.999999999999999, 4, 8.087415631104118], [6.999999999999999, 6, 7.197811937711704], [4.999999999999999, 4, 7.7306220779043615], [4.999999999999999, 4, 8.14427660213801], [7.0, 6, 8.033091632202481], [4.999999999999999, 4, 7.966501108259317], [7.0, 6, 7.656127749637401], [7.000000000000002, 4, 8.613414860026737], [9.000000000000002, 6, 8.024129868386668], [7.000000000000002, 4, 8.60379268112961], [8.999999999999996, 5, 9.222102927431049], [9.999999999999998, 6, 8.048785206349116], [8.0, 4, 8.75322359204392], [9.999999999999996, 4, 8.937392961386614], [10.999999999999998, 5, 9.347207901952507], [10.999999999999998, 6, 8.339865451619254], [10.999999999999998, 6, 8.538563233314969], [9.999999999999998, 4, 9.211690175544362], [10.999999999999998, 5, 9.718226530516892], [10.999999999999996, 6, 10.049604780717459], [8.999999999999998, 6, 8.807470823964925], [10.999999999999996, 4, 9.964513341213918], [10.0, 4, 9.807956104896228], [10.0, 6, 10.006736081501554], [8.0, 6, 8.593364320054672], [6.0, 6, 8.182915340909574], [8.0, 4, 9.562175158059949], [8.0, 6, 9.691201490806714], [8.0, 6, 9.286153004329533], [5.999999999999999, 6, 7.861325272524674], [8.0, 4, 9.10573530624099], [6.999999999999997, 4, 8.619855039182822], [5.0, 6, 7.4928859199209565], [5.0, 6, 7.492886008664898], [2.9999999999999996, 6, 7.152872088897676], [5.000000000000002, 4, 8.125315682765905], [5.000000000000002, 6, 8.555491698375787], [3.0000000000000004, 6, 6.9659454190706285], [4.999999999999999, 4, 8.042061226551311], [4.999999999999999, 6, 8.324038093860763], [2.999999999999999, 4, 7.9656367696841635], [0.9999999999999997, 6, 6.891444750183226], [2.999999999999999, 4, 7.922665154280099], [0.0, 6, 6.870100107516586], [1.9999999999999998, 6, 6.915885275368425], [1.9999999999999998, 4, 7.932346454155817], [5.000000000000001, 5, 9.220162295598117], [6.0, 6, 8.379445257881368], [5.999999999999996, 6, 8.85250686759371], [4.000000000000002, 4, 9.15045874987959], [4.999999999999997, 5, 9.83926181704708], [6.999999999999999, 6, 10.561323704411553], [6.999999999999999, 6, 9.401747923873867], [4.999999999999998, 4, 10.294363243138658], [6.000000000000001, 4, 10.300691113222276], [8.000000000000005, 6, 10.55826411203685], [8.000000000000005, 6, 9.284069385740338], [8.999999999999996, 6, 8.817892718630473], [7.000000000000001, 4, 10.024258504208582], [8.999999999999996, 6, 10.164517001674295], [9.000000000000004, 6, 9.898460836339439], [9.000000000000004, 6, 8.465783500529811], [7.000000000000002, 4, 9.71214987624364], [9.000000000000005, 4, 9.222882053905545], [11.0, 6, 8.053420041454665], [11.0, 6, 8.053420041323651], [9.000000000000005, 4, 8.654360651627899], [11.000000000000004, 6, 8.988989487097307], [11.000000000000004, 6, 7.596091937671468], [11.000000000000007, 6, 7.296156797245041], [9.000000000000002, 4, 8.506836174297698], [11.000000000000007, 6, 8.747804191457268], [11.000000000000002, 4, 8.275102107151653], [9.999999999999998, 6, 7.088260625808986], [11.000000000000002, 4, 8.312773405936507], [9.000000000000002, 6, 6.981913575701756], [9.000000000000002, 6, 6.98191357584363], [11.000000000000005, 4, 8.14504876767344], [9.000000000000004, 4, 7.8739249308046535], [7.0, 6, 7.308938316482878], [7.0, 6, 7.1636329621564165], [8.0, 4, 8.078461309673132], [8.0, 4, 8.057573370225548], [6.000000000000002, 6, 6.999393430413201], [5.000000000000002, 6, 6.832043820752572], [5.000000000000002, 6, 6.850365676800186], [7.000000000000003, 4, 8.021926362238807], [5.0, 6, 6.586988193607051], [6.999999999999999, 4, 7.833510466956622], [6.999999999999999, 4, 7.801300312521741], [7.0, 4, 7.783914677783453], [7.0, 4, 7.8316770581670685], [5.000000000000003, 6, 6.6319672110258345], [6.000000000000001, 4, 7.568935205065793], [4.000000000000001, 6, 6.581288288571006], [4.000000000000001, 6, 6.627957730518524], [3.0000000000000013, 6, 6.6169500097603775], [5.000000000000001, 6, 7.707369335318676], [5.000000000000001, 4, 7.558075857902458], [3.0, 6, 0.0], [2.0, 6, 2.031621094627372], [4.0, 4, 2.7594495280866154], [3.9999999999999996, 4, 2.5386102136887185], [1.9999999999999998, 4, 2.538610731024842], [2.9999999999999996, 5, 0.0], [3.0, 4, 3.375790482689243], [1.9999999999999998, 3, 1.1485141834711698], [1.9999999999999998, 5, 2.7539826209075216], [0.0, 3, 3.994985767759145], [1.9999999999999998, 3, 5.305242051849915], [0, 1, inf], [10.000000000000002, 5, 8.978437538663481], [12.0, 7, 7.96065490798573], [10.999999999999996, 6, 8.296750724082305], [11.000000000000004, 7, 7.801493776203306], [9.999999999999996, 5, 8.705241872590612], [9.999999999999996, 5, 8.694596259235809], [8.999999999999995, 7, 7.691490880346151], [11.000000000000002, 5, 8.575910080320474], [11.000000000000002, 5, 8.702766211630887], [9.000000000000002, 5, 8.655876107735688], [9.000000000000002, 5, 8.781408319213089], [7.000000000000003, 7, 7.7921692343821345], [9.000000000000005, 5, 9.101338515196337], [7.000000000000001, 7, 7.971680434012155], [7.000000000000001, 7, 7.912362607055435], [7.000000000000001, 6, 8.301852526923007], [6.0, 7, 7.716818284585452], [8.000000000000004, 5, 8.9190665697081], [5.000000000000001, 7, 7.470167589766118], [5.000000000000001, 7, 7.447891129590869], [7.000000000000001, 5, 8.55837665192882], [6.000000000000002, 6, 8.145152712788624], [6.000000000000002, 5, 8.233190825555615], [3.9999999999999996, 7, 7.276523878066056], [3.000000000000001, 7, 7.922137758871693], [5.0, 5, 7.944847862249228], [4.000000000000001, 7, 7.315273899817321], [3.9999999999999996, 5, 8.385073227354187], [1.9999999999999998, 7, 7.392203943468797], [3.9999999999999996, 5, 8.326326581178517], [4.0, 6, 8.304097927626945], [2.0, 7, 7.401817336302823], [4.0, 5, 8.634847488523901], [1.9999999999999996, 5, 8.259415153426884], [1.9999999999999996, 6, 8.222704527468398], [0.0, 7, 7.343078507014523]]\n"
     ]
    }
   ],
   "source": [
    "# print(vpart_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97vGU3-p6G8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ######### SPLIT DATASET INTO 2 --> TRAINING & TESTING #########\n",
    "\n",
    "# ### x --> 125000 * 2 [2d arr]\n",
    "# ### y --> 125000 * 1 [2d arr]\n",
    "\n",
    "# ### then split x --> x_train, x_test\n",
    "# ### then split y --> y_train, y_test\n",
    "\n",
    "# ###############################################################\n",
    "\n",
    "# row, col = (125000, 2)\n",
    "# x_complete = [[0 for n in range(col)] for m in range(row)]\n",
    "# y_complete = []\n",
    "# i=0\n",
    "# for key in state_space:\n",
    "\n",
    "#     agent, prey, pred = key\n",
    "#     agent_prey = len(g.BFS(agent, prey))-1\n",
    "#     x_complete[i][0] = agent_prey\n",
    "#     agent_pred = len(g.BFS(agent, pred))-1\n",
    "#     x_complete[i][1] = agent_pred\n",
    "\n",
    "#     # y_complete[i] = state_space[key][1]\n",
    "#     y_complete.append(state_space[key][1])\n",
    "\n",
    "#     i += 1\n",
    "\n",
    "# # y_complete[y_complete == math.inf] = 100000\n",
    "# for j in range(len(y_complete)):\n",
    "#     if y_complete[j] == math.inf:\n",
    "#         y_complete[j] = 100\n",
    "\n",
    "# # print(x_complete)\n",
    "# ###### TRAINING SPLIT #######\n",
    "\n",
    "# row, col = (100000, 2)\n",
    "# x_train = [[0 for n in range(col)] for m in range(row)]\n",
    "# y_train = []\n",
    "\n",
    "# for i in range(100000):\n",
    "#     x_train[i][0] = x_complete[i][0]\n",
    "#     x_train[i][1] = x_complete[i][1]\n",
    "#     y_train.append(y_complete[i])\n",
    "\n",
    "# x = x_train\n",
    "# y = y_train\n",
    "\n",
    "# x = np.array(x)\n",
    "# y = np.array(y)\n",
    "# y = y.reshape(100000, 1)\n",
    "# print(x, x.shape)\n",
    "# print(y, y.shape)\n",
    "# # print(x)\n",
    "\n",
    "# ###### TESTING SPLIT #######\n",
    "\n",
    "# row, col = (25000, 2)\n",
    "# x_test = [[0 for n in range(col)] for m in range(row)]\n",
    "# y_test = []\n",
    "\n",
    "# for i in range(100000, 125000):\n",
    "#     x_test[i-100000][0] = x_complete[i-100000][0]\n",
    "#     x_test[i-100000][1] = x_complete[i-100000][1]\n",
    "#     y_test.append(y_complete[i-100000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6igVFrGrv0xv"
   },
   "outputs": [],
   "source": [
    "####### NEURAL NETWORK - MODEL \"V\" #########\n",
    "\n",
    "class NN:\n",
    "    \n",
    "    def __init__(self, layers = [2,4,3,1], learning_rate = 0.0005, loops = 5000):\n",
    "        \n",
    "        self.wb_dict = {}\n",
    "        self.layers = layers\n",
    "        self.loss = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loops = loops\n",
    "        # self.sample_size = None ###### NOT REQD.\n",
    "\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "\n",
    "    def data_split(self, state_space):\n",
    "        ######### SPLIT DATASET INTO 2 --> TRAINING & TESTING #########\n",
    "\n",
    "        ### x --> 125000 * 2 [2d arr]\n",
    "        ### y --> 125000 * 1 [2d arr]\n",
    "\n",
    "        ### then split x --> x_train(100000), x_test(25000)\n",
    "        ### then split y --> y_train(100000), y_test(25000)\n",
    "\n",
    "        ###############################################################\n",
    "\n",
    "        row, col = (125000, 2)\n",
    "        x_complete = [[0 for n in range(col)] for m in range(row)]\n",
    "        y_complete = []\n",
    "        i=0\n",
    "        for key in state_space:\n",
    "\n",
    "            agent, prey, pred = key\n",
    "            agent_prey = len(g.BFS(agent, prey))-1\n",
    "            x_complete[i][0] = agent_prey\n",
    "            agent_pred = len(g.BFS(agent, pred))-1\n",
    "            x_complete[i][1] = agent_pred\n",
    "\n",
    "            y_complete.append(state_space[key][1])\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "        for j in range(len(y_complete)):\n",
    "            if y_complete[j] == math.inf:\n",
    "                y_complete[j] = 100 ##### REPLACING INFINITY with LARGE FINITE value\n",
    "\n",
    "        ###### TRAINING SPLIT #######\n",
    "\n",
    "        row, col = (100000, 2)\n",
    "        x_train = [[0 for n in range(col)] for m in range(row)]\n",
    "        y_train = []\n",
    "\n",
    "        for i in range(100000):\n",
    "            x_train[i][0] = x_complete[i][0]\n",
    "            x_train[i][1] = x_complete[i][1]\n",
    "            y_train.append(y_complete[i])\n",
    "        \n",
    "        self.x = x_train\n",
    "        self.y = y_train\n",
    "        \n",
    "        self.x = np.array(self.x)\n",
    "        self.y = np.array(self.y)\n",
    "        self.y = self.y.reshape(100000, 1)\n",
    "        # print(self.x, self.x.shape)\n",
    "        # print(self.y, self.y.shape)\n",
    "        \n",
    "        ###### TESTING SPLIT #######\n",
    "\n",
    "        row, col = (25000, 2)\n",
    "        x_test = [[0 for n in range(col)] for m in range(row)]\n",
    "        y_test = []\n",
    "\n",
    "        for i in range(100000, 125000):\n",
    "            x_test[i-100000][0] = x_complete[i-100000][0]\n",
    "            x_test[i-100000][1] = x_complete[i-100000][1]\n",
    "            y_test.append(y_complete[i-100000])\n",
    "\n",
    "    def vpart_data_split(self, vpart_input):\n",
    "        row, col = (len(vpart_input), 2)\n",
    "        x_complete = [[0 for n in range(col)] for m in range(row)]\n",
    "        y_complete = []\n",
    "        \n",
    "        for i in range(len(vpart_input)):\n",
    "            x_complete[i][0] = vpart_input[i][0]\n",
    "            x_complete[i][1] = vpart_input[i][1]\n",
    "            \n",
    "            y_complete.append(vpart_input[i][2])\n",
    "        \n",
    "        for j in range(len(y_complete)):\n",
    "            if y_complete[j] == math.inf:\n",
    "                y_complete[j] = 100 ##### REPLACING INFINITY with LARGE FINITE value\n",
    "            \n",
    "        self.x = x_complete\n",
    "        self.y = y_complete\n",
    "        \n",
    "        self.x = np.array(self.x)\n",
    "        self.y = np.array(self.y)\n",
    "        self.y = self.y.reshape(len(y_complete), 1)    \n",
    "        \n",
    "    def weights(self):\n",
    "\n",
    "        np.random.seed(10)\n",
    "        self.wb_dict[\"w1\"] = np.random.randn(self.layers[0], self.layers[1])        \n",
    "        self.wb_dict[\"b1\"] = np.random.randn(self.layers[1])\n",
    "        self.wb_dict[\"w2\"] = np.random.randn(self.layers[1], self.layers[2])\n",
    "        self.wb_dict[\"b2\"] = np.random.randn(self.layers[2])\n",
    "        self.wb_dict[\"w3\"] = np.random.randn(self.layers[2], self.layers[3])\n",
    "        self.wb_dict[\"b3\"] = np.random.randn(self.layers[3])\n",
    "\n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def drelu(self, z):\n",
    "        z[z <= 0] = 0\n",
    "        z[z > 0] = 1\n",
    "        return z\n",
    "    \n",
    "    def lrelu (self,z):\n",
    "        return np.maximum(0.01*z, z)\n",
    "    \n",
    "    def dlrelu(self, z):\n",
    "        z[z <= 0] = 0.01\n",
    "        z[z > 0] = 1\n",
    "        return z\n",
    "    \n",
    "    def tanh(self, z):\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def dtanh(self, z):\n",
    "        return (1-np.tanh(z)**2)\n",
    "    \n",
    "    def sq_loss(self, y, yhat):\n",
    "        tmp = np.subtract(yhat, y)\n",
    "        loss = 0\n",
    "        for i in tmp:\n",
    "            loss += i*i\n",
    "        return loss/len(y)\n",
    "\n",
    "    def fwd_prop(self):\n",
    "\n",
    "        z1 = np.dot(self.x, self.wb_dict[\"w1\"]) + self.wb_dict[\"b1\"]\n",
    "        self.wb_dict[\"z1\"] = z1\n",
    "\n",
    "        # a1 = self.relu(z1) ###\n",
    "        a1 = self.tanh(z1)\n",
    "        self.wb_dict[\"a1\"] = a1\n",
    "\n",
    "        z2 = np.dot(a1 ,self.wb_dict[\"w2\"]) + self.wb_dict[\"b2\"]\n",
    "        self.wb_dict[\"z2\"] = z2\n",
    "\n",
    "        # a2 = self.relu(z2) ###\n",
    "        a2 = self.tanh(z2)\n",
    "        self.wb_dict[\"a2\"] = a2\n",
    "\n",
    "        z3 = np.dot(a2, self.wb_dict[\"w3\"]) + self.wb_dict[\"b3\"]\n",
    "        self.wb_dict[\"z3\"] = z3\n",
    "        # yhat = self.relu(z3)\n",
    "\n",
    "        yhat = np.array(z3)\n",
    "        # yhat = yhat.reshape(-1)\n",
    "\n",
    "        loss_val = self.sq_loss(self.y, yhat)\n",
    "        \n",
    "        return yhat, loss_val\n",
    "    \n",
    "    \n",
    "    def trained_fwd_prop(self, val):\n",
    "        \n",
    "#         fx = open(\"trained_weights\", \"wb\")\n",
    "#         pickle.dump(nn.wb_dict, f3)\n",
    "#         f3.close()\n",
    "        \n",
    "        # fx = open(\"trained_weights\", \"rb\")\n",
    "        # trained_weights =  pickle.load(fx)\n",
    "        ## wb_dict = pickle.load(f3)\n",
    "        # fx.close()\n",
    "        trained_weights = trained_weights_vpart\n",
    "        \n",
    "        z1 = np.dot(val, trained_weights[\"w1\"]) + trained_weights[\"b1\"]\n",
    "\n",
    "        # a1 = self.relu(z1) ###\n",
    "        a1 = self.tanh(z1)\n",
    "        \n",
    "        z2 = np.dot(a1 ,trained_weights[\"w2\"]) + trained_weights[\"b2\"]\n",
    "\n",
    "        # a2 = self.relu(z2) ###\n",
    "        a2 = self.tanh(z2)\n",
    "\n",
    "        z3 = np.dot(a2, trained_weights[\"w3\"]) + trained_weights[\"b3\"]\n",
    "\n",
    "        yhat = np.array(z3)\n",
    "\n",
    "        return yhat\n",
    "\n",
    "    def bwd_prop(self, yhat):\n",
    "\n",
    "        dl_yhat = 2 * (np.subtract(self.y, yhat))/len(self.y)\n",
    "        dl_z3 = dl_yhat\n",
    "        dl_a2 = np.dot(dl_z3, self.wb_dict[\"w3\"].transpose())\n",
    "        dl_w3 = np.dot(self.wb_dict[\"a2\"].transpose(), dl_z3)\n",
    "        dl_b3 = np.sum(dl_z3, axis = 0, keepdims = True)\n",
    "        # dl_z2 = dl_a2  * self.drelu(self.wb_dict[\"z2\"])####\n",
    "        dl_z2 = dl_a2  * self.dtanh(self.wb_dict[\"z2\"])\n",
    "        dl_a1 = np.dot(dl_z2, self.wb_dict[\"w2\"].transpose())\n",
    "        dl_w2 = np.dot(self.wb_dict[\"a1\"].transpose(), dl_z2)        \n",
    "        dl_b2 = np.sum(dl_z2, axis = 0, keepdims = True)\n",
    "        # dl_z1 = dl_a1  * self.drelu(self.wb_dict[\"z1\"])####\n",
    "        dl_z1 = dl_a1  * self.dtanh(self.wb_dict[\"z1\"])        \n",
    "        dl_w1 = np.dot(self.x.transpose(), dl_z1)\n",
    "        dl_b1 = np.sum(dl_z1, axis = 0, keepdims = True)\n",
    "        \n",
    "        #### WB_DICT IS UPDATED\n",
    "        self.wb_dict[\"w1\"] = self.wb_dict[\"w1\"] + self.learning_rate * dl_w1\n",
    "        self.wb_dict[\"w2\"] = self.wb_dict[\"w2\"] + self.learning_rate * dl_w2\n",
    "        self.wb_dict[\"w3\"] = self.wb_dict[\"w3\"] + self.learning_rate * dl_w3\n",
    "        self.wb_dict[\"b1\"] = self.wb_dict[\"b1\"] + self.learning_rate * dl_b1\n",
    "        self.wb_dict[\"b2\"] = self.wb_dict[\"b2\"] + self.learning_rate * dl_b2\n",
    "        self.wb_dict[\"b3\"] = self.wb_dict[\"b3\"] + self.learning_rate * dl_b3\n",
    "\n",
    "        \n",
    "    def plot_loss(self):\n",
    "\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Loops\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### RUN V ##########\n",
    "nn.data_split(state_space)\n",
    "nn.weights()\n",
    "for i in range(nn.loops):\n",
    "    # yhat, loss = nn.fwd_prop()\n",
    "    yhat, loss_val = nn.fwd_prop()\n",
    "    # loss_val = nn.sq_loss(yhat, nn.y)\n",
    "    nn.bwd_prop(yhat)\n",
    "    nn.loss.append(loss_val)\n",
    "    # print(\"--------------------\")\n",
    "    # print(\"LOSS: \", loss_val)\n",
    "    # print(\"LOOP: \", i)\n",
    "    # print(\"--------------------\")\n",
    "    # print(loss)\n",
    "nn.plot_loss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN ONLY WHEN TRAINING V ######\n",
    "\n",
    "fx = open(\"trained_weights\", \"wb\")\n",
    "pickle.dump(nn.wb_dict, fx)\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = open(\"trained_weights\", \"rb\")\n",
    "trained_weights =  pickle.load(fx)\n",
    "# wb_dict = pickle.load(f3)\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## RUN VPART #########\n",
    "# nn = NN()\n",
    "nn.vpart_data_split(vpart_input)\n",
    "nn.weights()\n",
    "for i in range(nn.loops):\n",
    "    # yhat, loss = nn.fwd_prop()\n",
    "    yhat, loss_val = nn.fwd_prop()\n",
    "    # loss_val = nn.sq_loss(yhat, nn.y)\n",
    "    nn.bwd_prop(yhat)\n",
    "    nn.loss.append(loss_val)\n",
    "    # print(\"--------------------\")\n",
    "    # print(\"LOSS: \", loss_val)\n",
    "    # print(\"LOOP: \", i)\n",
    "    # print(\"--------------------\")\n",
    "    # print(loss)\n",
    "nn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.8452868]\n"
     ]
    }
   ],
   "source": [
    "print(min(nn.loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN ONLY WHEN TRAINING VPart ######\n",
    "\n",
    "fx = open(\"trained_weights_vpart\", \"wb\")\n",
    "pickle.dump(nn.wb_dict, fx)\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = open(\"trained_weights_vpart\", \"rb\")\n",
    "trained_weights_vpart =  pickle.load(fx)\n",
    "# wb_dict = pickle.load(f3)\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_weights = trained_weights_vpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vAgent:\n",
    "    \n",
    "    def __init__(self, graph, prey_loc, pred_loc, state_space, dbg=False):\n",
    "\n",
    "        self.graph = graph\n",
    "        self.agent_loc = graph.get_rand_node()\n",
    "        self.dbg = dbg\n",
    "        self.prey_loc = prey_loc\n",
    "        self.pred_loc = pred_loc\n",
    "        self.state_space = copy.copy(state_space)\n",
    "\n",
    "        # while prey_loc == self.agent_loc or pred_loc == self.agent_loc or pred_loc == self.agent_loc + 1 or pred_loc == self.agent_loc - 1:\n",
    "        while prey_loc == self.agent_loc or pred_loc == self.agent_loc or state_space[(self.agent_loc, prey_loc, pred_loc)][1] == math.inf:\n",
    "            self.agent_loc = graph.get_rand_node()\n",
    "\n",
    "\n",
    "    def debug(self, *args):\n",
    "        if self.dbg:\n",
    "            print(\"agentV: \", args)\n",
    "\n",
    "\n",
    "    def isPrey(self, loc, prey_loc):\n",
    "        if self.agent_loc == prey_loc:\n",
    "            return True\n",
    "\n",
    "    def isPred(self, loc, pred_loc):\n",
    "        if self.agent_loc == pred_loc:\n",
    "            return True\n",
    "\n",
    "\n",
    "    def move(self, prey_loc, pred_loc, state_space):\n",
    "\n",
    "        agent_nbrs = self.graph.get_next_moves(self.agent_loc)\n",
    "\n",
    "        agent_nbr_util = {}\n",
    "        # prey_pred_dist = []\n",
    "        row, col = (1, 2)\n",
    "        prey_pred_dist = [[0 for n in range(col)] for m in range(row)]\n",
    "        \n",
    "        for nbr in agent_nbrs:\n",
    "            # tmp_dist = 0\n",
    "            # for i in range(len(prey_belief)):\n",
    "            #     tmp_dist += (len(g.BFS(nbr, prey_loc))-1) * prey_belief[i] #############\n",
    "            prey_pred_dist[0][0] = len(g.BFS(nbr, prey_loc))\n",
    "            prey_pred_dist[0][1] = len(g.BFS(nbr, pred_loc))\n",
    "\n",
    "            x = prey_pred_dist\n",
    "            x = np.array(prey_pred_dist)\n",
    "            \n",
    "            agent_nbr_util[nbr] = nn.trained_fwd_prop(x)\n",
    "\n",
    "        \n",
    "        min_util = min(agent_nbr_util.values())\n",
    "\n",
    "        for key in agent_nbr_util:\n",
    "            if min_util == agent_nbr_util[key]:\n",
    "                minm = key\n",
    "\n",
    "        self.agent_loc = minm\n",
    "\n",
    "        return self.agent_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class vPartAgent:\n",
    "    \n",
    "    def __init__(self, graph, prey_loc, pred_loc, prey_belief, state_space, dbg=False):\n",
    "\n",
    "        self.graph = graph\n",
    "        self.agent_loc = graph.get_rand_node()\n",
    "        self.dbg = dbg\n",
    "        self.prey_loc = prey_loc\n",
    "        self.pred_loc = pred_loc\n",
    "        self.state_space = copy.copy(state_space)\n",
    "        \n",
    "        self.vpart_dict = {}\n",
    "\n",
    "        # while prey_loc == self.agent_loc or pred_loc == self.agent_loc or pred_loc == self.agent_loc + 1 or pred_loc == self.agent_loc - 1:\n",
    "        while prey_loc == self.agent_loc or pred_loc == self.agent_loc or state_space[(self.agent_loc, prey_loc, pred_loc)][1] == math.inf:\n",
    "            self.agent_loc = graph.get_rand_node()\n",
    "\n",
    "        self.prey_belief = prey_belief\n",
    "        self.prey_belief[self.agent_loc] = 0\n",
    "\n",
    "    def debug(self, *args):\n",
    "        if self.dbg:\n",
    "            print(\"AgentVPart: \", args)\n",
    "\n",
    "\n",
    "    def isPrey(self, loc, prey_loc):\n",
    "        if self.agent_loc == prey_loc:\n",
    "            return True\n",
    "\n",
    "    def isPred(self, loc, pred_loc):\n",
    "        if self.agent_loc == pred_loc:\n",
    "            return True\n",
    "\n",
    "    def survey(self, prey_belief):\n",
    "        ## look at current list of belief - select max prob nodes (if multiple - select one at random)\n",
    "        new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "\n",
    "        val_max = max(prey_belief)\n",
    "        # idx_max = 0 ## not needed\n",
    "        idx_max_list = []\n",
    "\n",
    "        for i in range(len(prey_belief)):\n",
    "            if prey_belief[i] >= val_max:\n",
    "                # val_max = prey_belief[i]\n",
    "                idx_max_list.append(i)\n",
    "\n",
    "        rand_idx_max = random.choice(idx_max_list)\n",
    "\n",
    "        # ### check if prey is there or not\n",
    "        # \n",
    "        if self.isPrey(rand_idx_max, self.prey_loc):\n",
    "            # print(\"IS PREY EXECUTED: \", rand_idx_max)\n",
    "            for i in range(self.graph.node_num):\n",
    "                prey_belief[i] = 0.0\n",
    "            prey_belief[rand_idx_max] = 1.0\n",
    "            # print (\"ISPREY: \", prey_belief)\n",
    "            return prey_belief\n",
    "        #     update_belief ## according to prey found in survey logic\n",
    "                \n",
    "        else:\n",
    "        #     update_belief ## according to prey not found in survey logic\n",
    "            for i in range(self.graph.node_num):\n",
    "                # denom = sum(prey_belief)-prey_belief[rand_idx_max]\n",
    "                denom = 1-prey_belief[rand_idx_max]\n",
    "                new_prey_belief[i] = prey_belief[i]/denom\n",
    "                new_prey_belief[rand_idx_max] = 0.0\n",
    "\n",
    "        prey_belief = new_prey_belief\n",
    "        return prey_belief\n",
    "\n",
    "    def agent_move_prey_belief(self, prey_loc, prey_belief):\n",
    "\n",
    "        new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "        # new_prey_belief = prey_belief\n",
    "\n",
    "        if self.isPrey(self.agent_loc, prey_loc):\n",
    "            for i in range(self.graph.node_num): ###///this will not actually happen since the game would be over\n",
    "                prey_belief[i] = 0.0\n",
    "            prey_belief[self.agent_loc] = 1.0\n",
    "            return prey_belief  \n",
    "        \n",
    "        else:\n",
    "        #   update_belief ## according to prey not found in survey logic\n",
    "            for i in range(self.graph.node_num):\n",
    "                # denom = sum(prey_belief)-prey_belief[self.agent_loc]\n",
    "                denom = 1.0-prey_belief[self.agent_loc]\n",
    "                new_prey_belief[i] = prey_belief[i]/denom\n",
    "                new_prey_belief[self.agent_loc] = 0.0\n",
    "\n",
    "        prey_belief = new_prey_belief\n",
    "        return prey_belief\n",
    "\n",
    "    def prey_move_prey_belief(self, prey_loc, prey_belief):\n",
    "\n",
    "        new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "        # new_prey_belief = prey_belief\n",
    "\n",
    "        for i in range(self.graph.node_num):\n",
    "            nbrs_i = self.graph.get_next_moves(i)\n",
    "            nbrs_i.append(i)\n",
    "            for nbr in nbrs_i:\n",
    "                denom = self.graph.get_deg(nbr) + 1\n",
    "                new_prey_belief[i] += prey_belief[nbr] / denom\n",
    "\n",
    "        prey_belief = new_prey_belief\n",
    "\n",
    "        prey_belief = self.agent_move_prey_belief(prey_loc, prey_belief)\n",
    "\n",
    "        # prey_belief = new_prey_belief\n",
    "        return prey_belief\n",
    "\n",
    "\n",
    "    def move(self, prey_loc, pred_loc, prey_belief, state_space):\n",
    "\n",
    "        prey_belief = self.survey(prey_belief)\n",
    "\n",
    "        agent_nbrs = self.graph.get_next_moves(self.agent_loc)\n",
    "\n",
    "        agent_nbr_util = {}\n",
    "        tmp_list = [] ##########\n",
    "        for nbr in agent_nbrs:\n",
    "            # agent_nbr_util[nbr] = state_space[(nbr, prey_loc, pred_loc)][1]\n",
    "            tmp = 0\n",
    "            tmp_dist = 0 ###########\n",
    "            tmp2_list = [] ##########\n",
    "            for i in range(len(prey_belief)):\n",
    "                if state_space[(nbr, i, pred_loc)][1] == math.inf:\n",
    "                    tmp = math.inf\n",
    "                    break\n",
    "                    \n",
    "                tmp += state_space[(nbr, i, pred_loc)][1] * prey_belief[i]\n",
    "                tmp_dist += (len(g.BFS(nbr, prey_loc))-1) * prey_belief[i] #############\n",
    "                \n",
    "            agent_nbr_util[nbr] = tmp\n",
    "            \n",
    "            tmp2_list.append(tmp_dist) #################\n",
    "            tmp2_list.append((len(g.BFS(nbr, pred_loc))-1)) #################\n",
    "            tmp2_list.append(tmp) #################\n",
    "            \n",
    "            tmp_list.append(tmp2_list) ###############\n",
    "            \n",
    "        min_util = min(agent_nbr_util.values())\n",
    "        agentUPart.debug(\"min_util\", min_util)\n",
    "        for key in agent_nbr_util:\n",
    "            if min_util == agent_nbr_util[key]:\n",
    "                minm = key\n",
    "\n",
    "        agentUPart.debug(\"AGENT NBR UTIL: \", agent_nbr_util, \"(\",nbr, prey_loc, pred_loc,\")\")\n",
    "\n",
    "        self.agent_loc = minm\n",
    "\n",
    "        prey_belief = self.agent_move_prey_belief(prey_loc, prey_belief)\n",
    "\n",
    "        return self.agent_loc, tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g1.gpickle\")\n",
    "threshold = 5000\n",
    "loops = 3000\n",
    "hung = 0\n",
    "cnt = 0\n",
    "ans = 0\n",
    "\n",
    "survival = []\n",
    "vpart_data = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(loops):\n",
    "    preyVPart = Prey(g)\n",
    "    predVPart = Predator(g)\n",
    "    prey_belief = [1/(g.node_num-1)]*(g.node_num) ### [1/49]*50\n",
    "\n",
    "    agentVPart = vPartAgent(g, preyVPart.loc, predVPart.loc, prey_belief, state_space, False)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while agentVPart.agent_loc != preyVPart.loc and agentVPart.agent_loc != predVPart.loc:\n",
    "        \n",
    "        if count > threshold:\n",
    "            print(\"HUNG SIMULATION\")\n",
    "            hung += 1\n",
    "            continue\n",
    "\n",
    "        # agentVPart.debug(\"BEFORE\", agentVPart.agent_loc, preyVPart.loc, predVPart.loc)\n",
    "\n",
    "        agentVPart.agent_loc, tmp_list = agentVPart.move(preyVPart.loc, predVPart.loc, prey_belief, state_space)\n",
    "        for data in tmp_list:\n",
    "            vpart_data.append(data)\n",
    "        prey_belief = agentVPart.agent_move_prey_belief(preyVPart.loc, prey_belief)\n",
    "\n",
    "        if agentVPart.isPred(agentVPart.agent_loc, predVPart.loc) and agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "\n",
    "        elif agentVPart.isPred(agentVPart.agent_loc, predVPart.loc):\n",
    "            print(False, agentVPart.agent_loc, preyVPart.loc, predVPart.loc)\n",
    "            continue\n",
    "\n",
    "        elif agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "        \n",
    "        preyVPart.loc = preyVPart.move()\n",
    "        prey_belief = agentVPart.prey_move_prey_belief(preyVPart.loc, prey_belief) \n",
    "        \n",
    "        predVPart.loc = predVPart.move(agentVPart.agent_loc)\n",
    "        \n",
    "        if agentVPart.isPred(agentVPart.agent_loc, predVPart.loc) and agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue\n",
    "\n",
    "        elif agentVPart.isPred(agentVPart.agent_loc, predVPart.loc):\n",
    "            print(False, agentVPart.agent_loc, preyVPart.loc)\n",
    "            continue\n",
    "\n",
    "        elif agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "            # print(True)\n",
    "            ans += 1\n",
    "            continue      \n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    cnt += 1\n",
    "    survival.append(count)\n",
    "    # print(\"cnt: \", cnt, \"Steps : \", count)\n",
    "\n",
    "    \n",
    "# print(vpart_data)\n",
    "print(\"============================\")\n",
    "print(\"CNT: \", cnt)\n",
    "print(\"TRUE: \", ans)\n",
    "print(\"FALSE: \", cnt-(ans+hung))\n",
    "print(\"HUNG: \", hung)\n",
    "# avg_steps = sum(survival)\n",
    "sum = 0\n",
    "for i in survival:\n",
    "    sum += i\n",
    "\n",
    "print(\"AVG. STEPS: \", sum/loops)\n",
    "print(\"============================\")\n",
    "######################################\n",
    "\n",
    "# fv = open(\"vpart_input\", \"wb\")\n",
    "# # nx.gpickle.\n",
    "# pickle.dump(vpart_data, fv)\n",
    "# fv.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # g1 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g1.gpickle\")\n",
    "# threshold = 5000\n",
    "# loops = 1000\n",
    "# hung = 0\n",
    "# cnt = 0\n",
    "# ans = 0\n",
    "\n",
    "# survival = []\n",
    "\n",
    "# for i in range(loops):\n",
    "#     preyV = Prey(g)\n",
    "#     predV = Predator(g)\n",
    "\n",
    "#     agentV = vPartAgent(g, preyV.loc, predV.loc, state_space, False)\n",
    "    \n",
    "#     count = 0\n",
    "    \n",
    "#     while agentV.agent_loc != preyV.loc and agentV.agent_loc != predV.loc:\n",
    "        \n",
    "#         if count > threshold:\n",
    "#             print(\"HUNG SIMULATION\")\n",
    "#             hung += 1\n",
    "#             continue\n",
    "\n",
    "#         agentV.debug(\"BEFORE\", agentV.agent_loc, preyV.loc, predV.loc)\n",
    "\n",
    "#         agentV.agent_loc = agentV.move(preyV.loc, predV.loc, state_space)\n",
    "        \n",
    "#         if agentV.isPred(agentV.agent_loc, predV.loc) and agentV.isPrey(agentV.agent_loc, preyV.loc):\n",
    "#             print(True)\n",
    "#             ans += 1\n",
    "#             continue\n",
    "\n",
    "#         elif agentV.isPred(agentV.agent_loc, predV.loc):\n",
    "#             print(False)\n",
    "#             continue\n",
    "\n",
    "#         elif agentV.isPrey(agentV.agent_loc, preyV.loc):\n",
    "#             print(True)\n",
    "#             ans += 1\n",
    "#             continue\n",
    "        \n",
    "#         preyV.loc = preyV.move()\n",
    "        \n",
    "#         predV.loc = predV.move(agentV.agent_loc)\n",
    "        \n",
    "#         if agentV.isPred(agentV.agent_loc, predV.loc) and agentV.isPrey(agentV.agent_loc, preyV.loc):\n",
    "#             print(True)\n",
    "#             ans += 1\n",
    "#             continue\n",
    "\n",
    "#         elif agentV.isPred(agentV.agent_loc, predV.loc):\n",
    "#             print(False)\n",
    "#             continue\n",
    "\n",
    "#         elif agentV.isPrey(agentV.agent_loc, preyV.loc):\n",
    "#             print(True)\n",
    "#             ans += 1\n",
    "#             continue      \n",
    "        \n",
    "#         count += 1\n",
    "\n",
    "#     cnt += 1\n",
    "#     survival.append(count)\n",
    "#     # print(\"cnt: \", cnt, \"Steps : \", count)\n",
    "\n",
    "\n",
    "# print(\"============================\")\n",
    "# print(\"CNT: \", cnt)\n",
    "# print(\"TRUE: \", ans)\n",
    "# print(\"FALSE: \", cnt-(ans+hung))\n",
    "# print(\"HUNG: \", hung)\n",
    "# # avg_steps = sum(survival)\n",
    "# sum = 0\n",
    "# for i in survival:\n",
    "#     sum += i\n",
    "\n",
    "# print(\"AVG. STEPS: \", sum/loops)\n",
    "# print(\"============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class vPartAgent:\n",
    "    \n",
    "#     def __init__(self, graph, prey_loc, pred_loc, prey_belief, state_space, dbg=False):\n",
    "\n",
    "#         self.graph = graph\n",
    "#         self.agent_loc = graph.get_rand_node()\n",
    "#         self.dbg = dbg\n",
    "#         self.prey_loc = prey_loc\n",
    "#         self.pred_loc = pred_loc\n",
    "#         self.state_space = copy.copy(state_space)\n",
    "        \n",
    "#         self.vpart_dict = {}\n",
    "\n",
    "#         # while prey_loc == self.agent_loc or pred_loc == self.agent_loc or pred_loc == self.agent_loc + 1 or pred_loc == self.agent_loc - 1:\n",
    "#         while prey_loc == self.agent_loc or pred_loc == self.agent_loc or state_space[(self.agent_loc, prey_loc, pred_loc)][1] == math.inf:\n",
    "#             self.agent_loc = graph.get_rand_node()\n",
    "\n",
    "#         self.prey_belief = prey_belief\n",
    "#         self.prey_belief[self.agent_loc] = 0\n",
    "\n",
    "#     def debug(self, *args):\n",
    "#         if self.dbg:\n",
    "#             print(\"AgentVPart: \", args)\n",
    "\n",
    "\n",
    "#     def isPrey(self, loc, prey_loc):\n",
    "#         if self.agent_loc == prey_loc:\n",
    "#             return True\n",
    "\n",
    "#     def isPred(self, loc, pred_loc):\n",
    "#         if self.agent_loc == pred_loc:\n",
    "#             return True\n",
    "\n",
    "#     def survey(self, prey_belief):\n",
    "#         ## look at current list of belief - select max prob nodes (if multiple - select one at random)\n",
    "#         new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "\n",
    "#         val_max = max(prey_belief)\n",
    "#         # idx_max = 0 ## not needed\n",
    "#         idx_max_list = []\n",
    "\n",
    "#         for i in range(len(prey_belief)):\n",
    "#             if prey_belief[i] >= val_max:\n",
    "#                 # val_max = prey_belief[i]\n",
    "#                 idx_max_list.append(i)\n",
    "\n",
    "#         rand_idx_max = random.choice(idx_max_list)\n",
    "\n",
    "#         # ### check if prey is there or not\n",
    "#         # \n",
    "#         if self.isPrey(rand_idx_max, self.prey_loc):\n",
    "#             # print(\"IS PREY EXECUTED: \", rand_idx_max)\n",
    "#             for i in range(self.graph.node_num):\n",
    "#                 prey_belief[i] = 0.0\n",
    "#             prey_belief[rand_idx_max] = 1.0\n",
    "#             # print (\"ISPREY: \", prey_belief)\n",
    "#             return prey_belief\n",
    "#         #     update_belief ## according to prey found in survey logic\n",
    "                \n",
    "#         else:\n",
    "#         #     update_belief ## according to prey not found in survey logic\n",
    "#             for i in range(self.graph.node_num):\n",
    "#                 # denom = sum(prey_belief)-prey_belief[rand_idx_max]\n",
    "#                 denom = 1-prey_belief[rand_idx_max]\n",
    "#                 new_prey_belief[i] = prey_belief[i]/denom\n",
    "#                 new_prey_belief[rand_idx_max] = 0.0\n",
    "\n",
    "#         prey_belief = new_prey_belief\n",
    "#         return prey_belief\n",
    "\n",
    "#     def agent_move_prey_belief(self, prey_loc, prey_belief):\n",
    "\n",
    "#         new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "#         # new_prey_belief = prey_belief\n",
    "\n",
    "#         if self.isPrey(self.agent_loc, prey_loc):\n",
    "#             for i in range(self.graph.node_num): ###///this will not actually happen since the game would be over\n",
    "#                 prey_belief[i] = 0.0\n",
    "#             prey_belief[self.agent_loc] = 1.0\n",
    "#             return prey_belief  \n",
    "        \n",
    "#         else:\n",
    "#         #   update_belief ## according to prey not found in survey logic\n",
    "#             for i in range(self.graph.node_num):\n",
    "#                 # denom = sum(prey_belief)-prey_belief[self.agent_loc]\n",
    "#                 denom = 1.0-prey_belief[self.agent_loc]\n",
    "#                 new_prey_belief[i] = prey_belief[i]/denom\n",
    "#                 new_prey_belief[self.agent_loc] = 0.0\n",
    "\n",
    "#         prey_belief = new_prey_belief\n",
    "#         return prey_belief\n",
    "\n",
    "#     def prey_move_prey_belief(self, prey_loc, prey_belief):\n",
    "\n",
    "#         new_prey_belief = [0.0]*(self.graph.node_num)\n",
    "#         # new_prey_belief = prey_belief\n",
    "\n",
    "#         for i in range(self.graph.node_num):\n",
    "#             nbrs_i = self.graph.get_next_moves(i)\n",
    "#             nbrs_i.append(i)\n",
    "#             for nbr in nbrs_i:\n",
    "#                 denom = self.graph.get_deg(nbr) + 1\n",
    "#                 new_prey_belief[i] += prey_belief[nbr] / denom\n",
    "\n",
    "#         prey_belief = new_prey_belief\n",
    "\n",
    "#         prey_belief = self.agent_move_prey_belief(prey_loc, prey_belief)\n",
    "\n",
    "#         # prey_belief = new_prey_belief\n",
    "#         return prey_belief\n",
    "\n",
    "\n",
    "#     def move(self, prey_loc, pred_loc, prey_belief, state_space):\n",
    "\n",
    "#         prey_belief = self.survey(prey_belief)\n",
    "\n",
    "#         agent_nbrs = self.graph.get_next_moves(self.agent_loc)\n",
    "\n",
    "#         agent_nbr_util = {}\n",
    "#         tmp_list = [] ##########\n",
    "#         for nbr in agent_nbrs:\n",
    "#             # agent_nbr_util[nbr] = state_space[(nbr, prey_loc, pred_loc)][1]\n",
    "#             tmp = 0\n",
    "#             tmp_dist = 0 ###########\n",
    "#             tmp2_list = [] ##########\n",
    "#             for i in range(len(prey_belief)):\n",
    "#                 if state_space[(nbr, i, pred_loc)][1] == math.inf:\n",
    "#                     tmp = math.inf\n",
    "#                     break\n",
    "                    \n",
    "#                 tmp += state_space[(nbr, i, pred_loc)][1] * prey_belief[i]\n",
    "#                 tmp_dist += (len(g.BFS(nbr, prey_loc))-1) * prey_belief[i] #############\n",
    "                \n",
    "#             agent_nbr_util[nbr] = tmp\n",
    "            \n",
    "#             tmp2_list.append(tmp_dist) #################\n",
    "#             tmp2_list.append((len(g.BFS(nbr, pred_loc))-1)) #################\n",
    "#             tmp2_list.append(tmp) #################\n",
    "            \n",
    "#             tmp_list.append(tmp2_list) ###############\n",
    "            \n",
    "#         min_util = min(agent_nbr_util.values())\n",
    "#         agentUPart.debug(\"min_util\", min_util)\n",
    "#         for key in agent_nbr_util:\n",
    "#             if min_util == agent_nbr_util[key]:\n",
    "#                 minm = key\n",
    "\n",
    "#         agentUPart.debug(\"AGENT NBR UTIL: \", agent_nbr_util, \"(\",nbr, prey_loc, pred_loc,\")\")\n",
    "\n",
    "#         self.agent_loc = minm\n",
    "\n",
    "#         prey_belief = self.agent_move_prey_belief(prey_loc, prey_belief)\n",
    "\n",
    "#         return self.agent_loc, tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # g1 = nx.read_gpickle(\"/content/drive/MyDrive/Colab Notebooks/g1.gpickle\")\n",
    "# threshold = 5000\n",
    "# loops = 3000\n",
    "# hung = 0\n",
    "# cnt = 0\n",
    "# ans = 0\n",
    "\n",
    "# survival = []\n",
    "# vpart_data = []\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(loops):\n",
    "#     preyVPart = Prey(g)\n",
    "#     predVPart = Predator(g)\n",
    "#     prey_belief = [1/(g.node_num-1)]*(g.node_num) ### [1/49]*50\n",
    "\n",
    "#     agentVPart = vPartAgent(g, preyVPart.loc, predVPart.loc, prey_belief, state_space, False)\n",
    "    \n",
    "#     count = 0\n",
    "    \n",
    "#     while agentVPart.agent_loc != preyVPart.loc and agentVPart.agent_loc != predVPart.loc:\n",
    "        \n",
    "#         if count > threshold:\n",
    "#             print(\"HUNG SIMULATION\")\n",
    "#             hung += 1\n",
    "#             continue\n",
    "\n",
    "#         # agentVPart.debVg(\"BEFORE\", agentVPart.agent_loc, preyVPart.loc, predVPart.loc)\n",
    "\n",
    "#         agentVPart.agent_loc, tmp_list = agentVPart.move(preyVPart.loc, predVPart.loc, prey_belief, state_space)\n",
    "#         for data in tmp_list:\n",
    "#             vpart_data.append(data)\n",
    "#         prey_belief = agentVPart.agent_move_prey_belief(preyVPart.loc, prey_belief)\n",
    "\n",
    "#         if agentVPart.isPred(agentVPart.agent_loc, predVPart.loc) and agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "#             # print(True)\n",
    "#             ans += 1\n",
    "#             continue\n",
    "\n",
    "#         elif agentVPart.isPred(agentVPart.agent_loc, predVPart.loc):\n",
    "#             print(False, agentVPart.agent_loc, preyVPart.loc, predVPart.loc)\n",
    "#             continue\n",
    "\n",
    "#         elif agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "#             # print(True)\n",
    "#             ans += 1\n",
    "#             continue\n",
    "        \n",
    "#         preyVPart.loc = preyVPart.move()\n",
    "#         prey_belief = agentVPart.prey_move_prey_belief(preyVPart.loc, prey_belief) \n",
    "        \n",
    "#         predVPart.loc = predVPart.move(agentVPart.agent_loc)\n",
    "        \n",
    "#         if agentVPart.isPred(agentVPart.agent_loc, predVPart.loc) and agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "#             # print(True)\n",
    "#             ans += 1\n",
    "#             continue\n",
    "\n",
    "#         elif agentVPart.isPred(agentVPart.agent_loc, predVPart.loc):\n",
    "#             print(False, agentVPart.agent_loc, preyVPart.loc)\n",
    "#             continue\n",
    "\n",
    "#         elif agentVPart.isPrey(agentVPart.agent_loc, preyVPart.loc):\n",
    "#             # print(True)\n",
    "#             ans += 1\n",
    "#             continue      \n",
    "        \n",
    "#         count += 1\n",
    "\n",
    "#     cnt += 1\n",
    "#     survival.append(count)\n",
    "#     # print(\"cnt: \", cnt, \"Steps : \", count)\n",
    "\n",
    "    \n",
    "# # print(vpart_data)\n",
    "# print(\"============================\")\n",
    "# print(\"CNT: \", cnt)\n",
    "# print(\"TRUE: \", ans)\n",
    "# print(\"FALSE: \", cnt-(ans+hung))\n",
    "# print(\"HUNG: \", hung)\n",
    "# # avg_steps = sum(survival)\n",
    "# sum = 0\n",
    "# for i in survival:\n",
    "#     sum += i\n",
    "\n",
    "# print(\"AVG. STEPS: \", sum/loops)\n",
    "# print(\"============================\")\n",
    "# ######################################\n",
    "\n",
    "# # fv = open(\"vpart_input\", \"wb\")\n",
    "# # # nx.gpickle.\n",
    "# # pickle.dump(vpart_data, fv)\n",
    "# # fv.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
